● فرض کنیم لاگگیری برای هر  requestخیلی سنگین بشه. مثلاً نیاز باشه در لحظه اطلاعات لاگ رو به یه
سرویس جانبی یا دیتابیس دیگه بفرستی. چه راهحلی پیشنهاد میدی که لاگگیری باعث افت سرعت
سرویس اصلی نشه؟

1. لاگ گیری غیرهمزمان(async): می تونه با لاگ گیری در پس زمینه به ما کمک بکند تا درخواست های اصلی بلاک نشن
2. استفاده از صف: میتونیم لاگ ها رو در یک صف قرار بدیم مثل ردیس  و یا کافکا و یک کانسیومر جداگانه اون ها رو مصرف کنه
3. ارسال لاگ ها به صورت دسته ای تا فشار شبکه پایین بیاد


#--------------------------------------
● اگه فردا قراره این سیستم به صورت  multi-instanceروی چند سرور  deployبشه، چه چیزهایی باید
تغییر کنه؟ چه dependencyهایی باید جدا بشن یا  externalبشن؟ چه ریسکهایی باید مدیریت
بشن؟

1. دیتابیس برای ذخیره url, visits به صورت مرکزی باقی بماند
2. یک ردیس مشترک برای همه ی instance ها میاریم بالا تا شمارش هماهنگ باشد و تاحدودی بهینه
3. اگر کافکا داشتیم همه ی instance ها از یک kafka cluster مشترک برای ارسال event ها استفاده کنند
4. تماما باید stateless باشند و از حافظه ی داخلی instance ها نباید استفاده بشه. همگی باید در دیتابیس و ردیس نگهداری بشن.
5. کانفیگ ها مثلا .env فایل و باید برای همه ی instance ها مناسب باشند و تنظیم شده باشن.
6. load balancer بیاریم بالا مثل nginx که بار رو مدیریت و پخش کنه

#----------------------------------------
 فرض کن قراره یک کمپین تبلیغاتی اجرا بشه که ترافیک سنگینی به سرویس وارد میکنه چه تصمیمهایی گرفتی یا میتونی بگیری که سرویس  down نشه؟

1. هندل کردن درخواست ها با خود fastapi و استفاده از async , asyncsession, sqlalchemy که به ما کمک
   میکنند تا تعداد زیادی درخواست رو هندل کنیم به صورت بهینه.
2. همانطور که از قبل ذکر شده و در کد هم استفاده شده تا حدودی، میتونیم از کشینگ استفاده کنیم تا db heat کمتری داشته باشیم 
3. صف کردن که تاحدودی و تابخشی توی کد اومده که درخواست ها رو با کافکا صف کنیم و مدیریت کنیم تا از سمت دیگه کانسیومر مصرف کنه
4. استفاده از LOAD BALANCER مثل nginx تا بار رو پخش کنه و مدیریت
5. استفاده از connection pooling چون قابلیت تنظیم و کانفیگ داره و بهینه هست
6. استفاده از rate limiting که درخواست ها بهینه تر بشوند 
7. استفاده از pagination هم میتواند مفید باشد 



